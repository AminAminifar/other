{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras import backend \n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import metrics\n",
    "from keras import models, layers\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "data_df = pd.read_csv('handwritten_digits_images.csv', header=None)\n",
    "labels_df = pd.read_csv('handwritten_digits_labels.csv', header=None)\n",
    "data = data_df.to_numpy()\n",
    "labels = labels_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197414</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.991206</td>\n",
       "      <td>4.256304</td>\n",
       "      <td>2.783732</td>\n",
       "      <td>1.561822</td>\n",
       "      <td>1.553796</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7    \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           8        9    ...           774           775           776  \\\n",
       "count  70000.0  70000.0  ...  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.0      0.0  ...      0.197414      0.099543      0.046629   \n",
       "std        0.0      0.0  ...      5.991206      4.256304      2.783732   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "                777           778           779      780      781      782  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.0  70000.0  70000.0   \n",
       "mean       0.016614      0.012957      0.001714      0.0      0.0      0.0   \n",
       "std        1.561822      1.553796      0.320889      0.0      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "max      253.000000    254.000000     62.000000      0.0      0.0      0.0   \n",
       "\n",
       "           783  \n",
       "count  70000.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: \n",
      " [0 1 2 3 4 5 6 7 8 9]\n",
      "Num of samples for each class respectively: \n",
      " [6903 7877 6990 7141 6824 6313 6876 7293 6825 6958]\n",
      "Ratio of samples for each class respectively: \n",
      " [0.09861429 0.11252857 0.09985714 0.10201429 0.09748571 0.09018571\n",
      " 0.09822857 0.10418571 0.0975     0.0994    ]\n"
     ]
    }
   ],
   "source": [
    "# Ratios of number of samples with respect to their classes\n",
    "unique_nums, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(\"Class Labels: \\n\", unique_nums)\n",
    "print(\"Num of samples for each class respectively: \\n\", counts)\n",
    "print(\"Ratio of samples for each class respectively: \\n\", counts/sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ac3f433e48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADa9JREFUeJzt3X+oXPWZx/HPYzZFSCr+yCRe07i3baSsCWwqQ1iwqLVY0lK4Bo0mSIlQN/4RxUDUVRHiHxZkNc1GqIV0jU1JmrbQWCMEbRDFVtbq3CDVmt3tRa9tNiF3gpLYf6w3efaPe1KuyT3fmcycOWfufd4vCDNznnPueTLJ556Z+Z45X3N3AYjnvKobAFANwg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKh/KHNn8+bN88HBwTJ3CYQyOjqqY8eOWTvrdhV+M1shaaukWZL+090fS60/ODioRqPRzS4BJNTr9bbX7fhlv5nNkvRDSd+SdKWkNWZ2Zac/D0C5unnPv1zSiLu/5+5/k/RzSUPFtAWg17oJ/0JJf5n0+FC27DPMbJ2ZNcys0Ww2u9gdgCJ1E/6pPlQ46/vB7r7N3evuXq/Val3sDkCRugn/IUmLJj3+gqTD3bUDoCzdhP9NSVeY2RfN7HOSVkvaW0xbAHqt46E+dx83s7skvaiJob7t7v7HwjoD0FNdjfO7+z5J+wrqBUCJOL0XCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBKnaIbnRkfH0/W77///tzali1bkttu3LgxWX/iiSeSdUxfHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiuxvnNbFTSx5JOShp393oRTeGzdu/enaxv3bo1tzY0NJTc9p577umoJ0x/RZzk83V3P1bAzwFQIl72A0F1G36X9BszGzazdUU0BKAc3b7sv9rdD5vZfEn7zey/3f3VyStkvxTWSdLll1/e5e4AFKWrI7+7H85uxyQ9K2n5FOtsc/e6u9drtVo3uwNQoI7Db2ZzzOzzp+9L+qakd4pqDEBvdfOyf4GkZ83s9M/5mbu/UEhXAHqu4/C7+3uS/rnAXpDj4YcfTtYvvfTS3NpTTz2V3Payyy7rqCdMfwz1AUERfiAowg8ERfiBoAg/EBThB4Li0t3TgLsn63v27MmtdTuUd+rUqWR93759yXrqsuJ33HFHcttbb701WV+4cGGyjjSO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP800B2zYRcc+fO7dm+h4eHk/VWlwZPnaNw3333JbfdvHlzsv76668n64sWLUrWo+PIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc7fB0ZGRpL1sbGxkjo5W6vpwS+88MJkfefOnbm1Y8fSkzvffvvtyfrevXuT9fXr1yfr0XHkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgWo7zm9l2Sd+RNObuS7NlF0v6haRBSaOSbnH3j3rX5sy2ePHiZH3+/PkldXK2jz5K/7Pu378/Wb/qqqtyaydPnkxum5qPQGp9fgTS2jny/0TSijOWPSDpJXe/QtJL2WMA00jL8Lv7q5I+PGPxkKQd2f0dkm4suC8APdbpe/4F7n5EkrLb6l6XAuhIzz/wM7N1ZtYws0az2ez17gC0qdPwHzWzAUnKbnO/eeLu29y97u71Wq3W4e4AFK3T8O+VtDa7v1bSc8W0A6AsLcNvZrsl/Zekr5jZITP7nqTHJN1gZn+SdEP2GMA00nKc393X5JS+UXAvyHHBBRck6/PmzevZvrdu3Zqsz5o1q+Of3WrbgYGBZP2ZZ55J1h988MHcWpXnTvQLzvADgiL8QFCEHwiK8ANBEX4gKMIPBMWlu6eB48ePJ+upS2AvWLCgq323Gmas0okTJ5L1w4cP59YY6uPID4RF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc4/DZhZ1S1gBuLIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc4/A7z77ru5tSVLlpTYSbGWLl1adQszGkd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq5Ti/mW2X9B1JY+6+NFv2iKR/ldTMVnvI3ff1qsno3D1Zf+WVV3Jrq1atKrib8lxzzTVVtzCjtXPk/4mkFVMs3+Luy7I/BB+YZlqG391flfRhCb0AKFE37/nvMrM/mNl2M7uosI4AlKLT8P9I0pclLZN0RNLmvBXNbJ2ZNcys0Ww281YDULKOwu/uR939pLufkvRjScsT625z97q712u1Wqd9AihYR+E3s4FJD1dKeqeYdgCUpZ2hvt2SrpM0z8wOSdok6TozWybJJY1KurOHPQLogZbhd/c1Uyx+uge9IEfU6/bv2rWr6hZmNM7wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbtngBdeeCG39umnnya3nT17dtHtFOb48ePJ+iWXXJKsL168uMh2ZhyO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP808C1116brO/cuTO39sknnyS3rXKcf3x8PFkfHh5O1u+9995kfe7cuefcUyQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb5p4HbbrstWU9d4vr5559PbrtmzVRXZi/H2NhYst5oNJL1tWvXFtlOOBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiColuP8ZrZI0k8lXSrplKRt7r7VzC6W9AtJg5JGJd3i7h/1rtW4Wn2ff8mSJbm1l19+ObntzTffnKx3+33/1LwBQ0NDyW1b/b0Z5+9OO0f+cUkb3f2fJP2LpPVmdqWkByS95O5XSHopewxgmmgZfnc/4u4HsvsfSzooaaGkIUk7stV2SLqxV00CKN45vec3s0FJX5X0e0kL3P2INPELQtL8opsD0Dtth9/M5kr6laQN7n7iHLZbZ2YNM2s0m81OegTQA22F38xmayL4u9x9T7b4qJkNZPUBSVN+S8Pdt7l73d3rtVqtiJ4BFKBl+M3MJD0t6aC7/2BSaa+k0x+3rpX0XPHtAeiVdr7Se7Wk70p628zeypY9JOkxSb80s+9J+rOkVb1pEeeff36yvnLlytzao48+mtx29erVyfr111+frLt7sr5hw4bc2oEDB5Lbvvbaa8n6nDlzknWktQy/u/9OkuWUv1FsOwDKwhl+QFCEHwiK8ANBEX4gKMIPBEX4gaC4dPcMsGnTptzayMhIctsVK1Yk6zfddFOy/sYbbyTr77//fm7t7rvvTm67fPnyZB3d4cgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzj8DnHde/u/wxx9/PLnt4OBgsv7iiy8m6x988EGy/uSTT+bW7rzzzuS2qb8XusezCwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBWavrrhepXq97o9EobX9ANPV6XY1GI+9S+5/BkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmoZfjNbZGYvm9lBM/ujmd2TLX/EzP7PzN7K/ny79+0CKEo7F/MYl7TR3Q+Y2eclDZvZ/qy2xd2f6F17AHqlZfjd/YikI9n9j83soKSFvW4MQG+d03t+MxuU9FVJv88W3WVmfzCz7WZ2Uc4268ysYWaNZrPZVbMAitN2+M1srqRfSdrg7ick/UjSlyUt08Qrg81Tbefu29y97u71Wq1WQMsAitBW+M1stiaCv8vd90iSux9195PufkrSjyUxqyIwjbTzab9JelrSQXf/waTlA5NWWynpneLbA9Ar7Xzaf7Wk70p628zeypY9JGmNmS2T5JJGJaWvwwygr7Tzaf/vJE31/eB9xbcDoCyc4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq1Cm6zawp6YNJi+ZJOlZaA+emX3vr174keutUkb39o7u3db28UsN/1s7NGu5er6yBhH7trV/7kuitU1X1xst+ICjCDwRVdfi3Vbz/lH7trV/7kuitU5X0Vul7fgDVqfrID6AilYTfzFaY2f+Y2YiZPVBFD3nMbNTM3s5mHm5U3Mt2Mxszs3cmLbvYzPab2Z+y2ymnSauot76YuTkxs3Slz12/zXhd+st+M5sl6X8l3SDpkKQ3Ja1x93dLbSSHmY1Kqrt75WPCZnaNpL9K+qm7L82W/bukD939sewX50Xu/m990tsjkv5a9czN2YQyA5NnlpZ0o6TbVeFzl+jrFlXwvFVx5F8uacTd33P3v0n6uaShCvroe+7+qqQPz1g8JGlHdn+HJv7zlC6nt77g7kfc/UB2/2NJp2eWrvS5S/RViSrCv1DSXyY9PqT+mvLbJf3GzIbNbF3VzUxhQTZt+unp0+dX3M+ZWs7cXKYzZpbum+eukxmvi1ZF+Kea/aefhhyudverJH1L0vrs5S3a09bMzWWZYmbpvtDpjNdFqyL8hyQtmvT4C5IOV9DHlNz9cHY7JulZ9d/sw0dPT5Ka3Y5V3M/f9dPMzVPNLK0+eO76acbrKsL/pqQrzOyLZvY5Sasl7a2gj7OY2ZzsgxiZ2RxJ31T/zT68V9La7P5aSc9V2Mtn9MvMzXkzS6vi567fZryu5CSfbCjjPyTNkrTd3b9fehNTMLMvaeJoL01MYvqzKnszs92SrtPEt76OStok6deSfinpckl/lrTK3Uv/4C2nt+s08dL17zM3n36PXXJvX5P0W0lvSzqVLX5IE++vK3vuEn2tUQXPG2f4AUFxhh8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaD+H3+F13KJ5cQYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing one of the samples\n",
    "ax = plt.axes()\n",
    "ax.imshow(data[0].reshape(28,28),cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop showing warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for selecting best k\n",
    "def KNN_select(X, Y, possible_ks=[3, 5, 10, 20]):\n",
    "    acc_list = []\n",
    "    for k in possible_ks:\n",
    "        print(\"training for k = %d\"%k)\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5)\n",
    "        acc_list.append(np.mean(scores))\n",
    "        print(\"for k = %d scores are :\"%k,scores)\n",
    "        print(\"=========================================\")\n",
    "    Best_k = possible_ks[np.argmax(acc_list)]\n",
    "    return Best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for selecting best number of trees for our decision tree alg.\n",
    "def DT_select(X, Y, possible_depths=[10,20]):\n",
    "    acc_list = []\n",
    "    for d in possible_depths:\n",
    "        print(\"training for depth = %d\"%d)\n",
    "        clf = DecisionTreeClassifier(random_state=0, max_depth=d)\n",
    "        scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5) \n",
    "        acc_list.append(np.mean(scores))\n",
    "        print(\"for depth = %d scores are :\"%d,scores)\n",
    "        print(\"=========================================\")\n",
    "    Best_depth = possible_depths[np.argmax(acc_list)]\n",
    "    return Best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for selecting best number of trees for our random forest alg.\n",
    "def RF_select(X, Y, possible_num_of_trees=[100, 300, 500, 1000]):\n",
    "    acc_list = []\n",
    "    for num in possible_num_of_trees:\n",
    "        print(\"training for %d trees\"%num)\n",
    "        clf = RandomForestClassifier(n_estimators=num)\n",
    "        scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5) \n",
    "        acc_list.append(np.mean(scores))\n",
    "        print(\"for %d trees scores are :\"%num,scores)\n",
    "        print(\"=========================================\")\n",
    "    Best_num_of_trees = possible_num_of_trees[np.argmax(acc_list)]\n",
    "    return Best_num_of_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "np.random.seed(seed)\n",
    "\n",
    "def KFold_split(X, Y, num_folds, seed):\n",
    "    KFold_splitter = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    X_train_folds = []\n",
    "    X_val_folds = []\n",
    "    Y_train_folds = []\n",
    "    Y_val_folds = []\n",
    "    for (kth_fold_train_idxs, kth_fold_val_idxs) in KFold_splitter.split(X, Y):\n",
    "        X_train_folds.append(X[kth_fold_train_idxs])\n",
    "        X_val_folds.append(X[kth_fold_val_idxs])\n",
    "        Y_train_folds.append(Y[kth_fold_train_idxs])\n",
    "        Y_val_folds.append(Y[kth_fold_val_idxs])\n",
    "    return X_train_folds, X_val_folds, Y_train_folds, Y_val_folds\n",
    "\n",
    "### Construct a simple fully-connected MLP with SGD:\n",
    "def build_MLP(input_shape, num_classes, activation_type, network_depth):\n",
    "    MLP = Sequential()\n",
    "    # Hidden layers (fully connected):\n",
    "    MLP.add(Dense(input_shape=input_shape, units=30, activation=activation_type))\n",
    "    if network_depth > 1:\n",
    "        for i in range(1,network_depth):\n",
    "            MLP.add(Dense(units=60, activation=activation_type))\n",
    "    # Output layer (fully-connected):\n",
    "    MLP.add(Dense(units=num_classes, \n",
    "                  activation='softmax'))\n",
    "    MLP.compile(loss=categorical_crossentropy,\n",
    "                optimizer='SGD',\n",
    "                metrics=['accuracy'])\n",
    "    return MLP\n",
    "\n",
    "def MLP_select(X, Y, possible_depths=[1,2,3,4,5],\n",
    "               possible_activation_functions=[\"sigmoid\", \"relu\"],\n",
    "               batch_sizes=[50,100,200,500],\n",
    "               num_epochs=[50,100,200,500]):\n",
    "    acc_list = [[[[0 for b in range(len(batch_sizes))]\n",
    "                  for e in range(len(num_epochs))]\n",
    "                 for a in range(len(possible_activation_functions))]\n",
    "                for d in range(len(possible_depths))]\n",
    "    input_shape = (X.shape[1], )\n",
    "    num_classes = 10\n",
    "    Y = to_categorical(Y, num_classes)\n",
    "    num_folds = 5\n",
    "    X_train_folds, X_val_folds, Y_train_folds, Y_val_folds = KFold_split(X, Y, num_folds, seed)\n",
    "    \n",
    "    depth_index = 0\n",
    "    for depth in possible_depths:\n",
    "        activation_function_index = 0\n",
    "        for activation_function in possible_activation_functions:\n",
    "            epoch_index = 0\n",
    "            for epoch in num_epochs:\n",
    "                batch_size_index = 0\n",
    "                for batch_size in batch_sizes:\n",
    "                    model = KerasClassifier(build_fn=build_MLP, input_shape=input_shape, num_classes=num_classes,\n",
    "                         activation_type=activation_function, network_depth=depth, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "                    \n",
    "                    print(\"training for Number of Hidden Layers:{}, Activation Function:{}, Num of Epocs:{}, Batch Size:{}\"\n",
    "                         .format(depth, activation_function,epoch,batch_size))\n",
    "                          \n",
    "                    for X_train_fold, X_val_fold, Y_train_fold, Y_val_fold in zip(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds):\n",
    "                        model.fit(X_train_fold, Y_train_fold)\n",
    "                        prediction = model.predict(X_val_fold)\n",
    "                        acc_list[depth_index][activation_function_index][epoch_index][batch_size_index] +=\\\n",
    "                            f1_score(np.argmax(Y_val_fold,axis=1), prediction, average='macro')/num_folds\n",
    "                    print(\"for Depth:{}, Activation Function:{}, Num of Epocs:{}, Batch Size:{} mean score is :\"\n",
    "                         .format(depth, activation_function,epoch,batch_size),\n",
    "                         acc_list[depth_index][activation_function_index][epoch_index][batch_size_index])\n",
    "                    print(\"=========================================\")\n",
    "                    batch_size_index = batch_size_index + 1\n",
    "                epoch_index = epoch_index + 1\n",
    "            activation_function_index = activation_function_index + 1\n",
    "        depth_index = depth_index + 1\n",
    "\n",
    "    \n",
    "\n",
    "    acc_list = np.array(acc_list)\n",
    "    best_depth_i, best_activation_function_i, best_num_epoch_i, best_batch_size_i = \\\n",
    "        np.unravel_index(acc_list.argmax(), acc_list.shape)\n",
    "    best_depth, best_activation_function, best_num_epoch, best_batch_size = \\\n",
    "        possible_depths[best_depth_i],\\\n",
    "        possible_activation_functions[best_activation_function_i],\\\n",
    "        num_epochs[best_num_epoch_i],\\\n",
    "        batch_sizes[best_batch_size_i]\n",
    "    \n",
    "    return best_depth, best_activation_function, best_num_epoch, best_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model_select(X, Y):\n",
    "#     print(\"################____KNN____#################\")\n",
    "#     #  Find the best model with respect to different values of K\n",
    "#     Best_k = KNN_select(X, Y, possible_ks=[5, 10])\n",
    "#     print(\"The best k is: \", Best_k)\n",
    "    \n",
    "    print(\"################____DT____#################\")\n",
    "    #  Find the best model with respect to different values of depth\n",
    "    Best_depth = DT_select(X, Y, possible_depths=[8, 15])\n",
    "    print(\"The best depth is: \", Best_depth)\n",
    "    \n",
    "    print(\"################____RF____#################\")\n",
    "    # Find the best model with respect to different number of trees\n",
    "    Best_num_of_trees = RF_select(X, Y, possible_num_of_trees=[100, 500])\n",
    "    print(\"The best num of trees is: \", Best_num_of_trees)\n",
    "    \n",
    "    print(\"################____MLP____#################\")\n",
    "    Best_num_of_hidden_layers, Best_activation_function, best_num_epoch, best_batch_size =\\\n",
    "                                                                    MLP_select(X, Y,\n",
    "                                                                    possible_depths=[0,1,7],\n",
    "                                                                    possible_activation_functions=[\"sigmoid\", \"relu\"],\n",
    "                                                                    batch_sizes=[15,30],\n",
    "                                                                    num_epochs=[25,50])\n",
    "    print(\"The best number of hidden layers is: \", Best_num_of_hidden_layers)\n",
    "    print(\"The best activation function is: \", Best_activation_function)\n",
    "    print(\"The best number of epocs is: \", best_num_epoch)\n",
    "    print(\"The best batchsize is: \", best_batch_size)\n",
    "    \n",
    "    print(\"========================Selection Between DT, RF, and MLP==========================\")\n",
    "    acc_list = [0 for i in range(3)]\n",
    "    \n",
    "#     #KNN\n",
    "#     clf = KNeighborsClassifier(n_neighbors=Best_k)\n",
    "#     scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5) \n",
    "#     acc_list[0] = np.mean(scores)\n",
    "#     print(\"K Neighbors Classifier Classification Performance: \",acc_list[0])\n",
    "#     print(\"=========================================\")\n",
    "\n",
    "    #DT\n",
    "    clf = DecisionTreeClassifier(random_state=0, max_depth=Best_depth)\n",
    "    scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5) \n",
    "    acc_list[0] = np.mean(scores)\n",
    "    print(\"Decision Tree Classification Performance: \",acc_list[0])\n",
    "    print(\"=========================================\")\n",
    "    \n",
    "    # RF\n",
    "    clf = RandomForestClassifier(n_estimators=Best_num_of_trees)\n",
    "    scores = cross_val_score(clf, X, Y, scoring='f1_macro', cv=5)\n",
    "    acc_list[1] = np.mean(scores)\n",
    "    print(\"Random Forest Classifier Classification Performance: \",acc_list[1])\n",
    "    print(\"=========================================\")\n",
    "    \n",
    "    #MLP\n",
    "    input_shape = (X.shape[1], )\n",
    "    num_classes = 10\n",
    "    Y = to_categorical(Y, num_classes)\n",
    "    num_folds = 5\n",
    "    clf = KerasClassifier(build_fn=build_MLP, input_shape=input_shape, num_classes=num_classes,\n",
    "            activation_type=Best_activation_function, network_depth=Best_num_of_hidden_layers,\n",
    "                          epochs=best_num_epoch, batch_size=best_batch_size, verbose=0)\n",
    "    X_train_folds, X_val_folds, Y_train_folds, Y_val_folds = KFold_split(X, Y, num_folds, seed)\n",
    "    for X_train_fold, X_val_fold, Y_train_fold, Y_val_fold in zip(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds):\n",
    "        clf.fit(X_train_fold, Y_train_fold)\n",
    "        prediction = clf.predict(X_val_fold)\n",
    "        acc_list [2] += f1_score(np.argmax(Y_val_fold,axis=1), prediction, average='macro')/num_folds\n",
    "    print(\"MLP Classifier Classification Performance: \",acc_list[2])\n",
    "    print(\"=========================================\")\n",
    "    \n",
    "    model_index = np.argmax(acc_list)\n",
    "    \n",
    "    if model_index==0:\n",
    "#         print(\"The best model is learnt by K Neighbors Classifier!\")\n",
    "#         model = KNeighborsClassifier(n_neighbors=Best_k)\n",
    "        print(\"The best model is learnt by Decision Tree Classifier!\")\n",
    "        model = DecisionTreeClassifier(random_state=0, max_depth=Best_depth)\n",
    "    elif model_index==1:\n",
    "        print(\"The best model is learnt by Random Forest Classifier!\")\n",
    "        model = RandomForestClassifier(n_estimators=Best_num_of_trees)\n",
    "    else:\n",
    "        print(\"The best model is learnt by MLP Classifier!\")\n",
    "        model = KerasClassifier(build_fn=build_MLP, input_shape=input_shape, num_classes=num_classes,\n",
    "                    activation_type=Best_activation_function, network_depth=Best_num_of_hidden_layers,\n",
    "                    epochs=best_num_epoch, batch_size=best_batch_size, verbose=0)\n",
    "        \n",
    "    return model_index, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A preprocessing of data can be needed as the dimentionality of data and number of samples are large\n",
    "# A model selection for dimentionality reduction\n",
    "def preprocess_data(X, Y):\n",
    "    \n",
    "    def dim_red_ae(data,n_dims_encoded=20):\n",
    "        input_layer = layers.Input(shape=(data.shape[1], ))\n",
    "        encoding_layer = layers.Dense(n_dims_encoded,activation='tanh')(input_layer)\n",
    "        decoding_layer = layers.Dense(data.shape[1],activation='tanh') (encoding_layer)\n",
    "        autoencoder = models.Model(input_layer, decoding_layer)\n",
    "        autoencoder.compile('adam', loss='mse')\n",
    "        autoencoder.fit(x = data, y = data, epochs=5)\n",
    "        encoder = models.Model(input_layer, encoding_layer)\n",
    "        return encoder,autoencoder\n",
    "    \n",
    "    acc_list = []\n",
    "    possible_dims = [300,400,500]\n",
    "    for dims in possible_dims:\n",
    "        print(\"training for %d dimensions\"%dims)\n",
    "        encoder,_ = dim_red_ae(X,dims)\n",
    "        encodings = encoder.predict(X)\n",
    "        clf = RandomForestClassifier().fit(encodings,Y)\n",
    "        scores = cross_val_score(clf, encodings, Y, cv=5)\n",
    "        acc_list.append(np.mean(scores))\n",
    "        print(\"for %d dims scores are :\"%dims,scores)\n",
    "        print(\"=========================================\")\n",
    "    best_dim = possible_dims[np.argmax(acc_list)]\n",
    "    \n",
    "    encoder,_ = dim_red_ae(X,best_dim)\n",
    "    processed_data = encoder.predict(X)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess the data\n",
    "# processed_data = preprocess_data(data, labels)\n",
    "# Devide data to train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################____DT____#################\n",
      "training for depth = 8\n",
      "for depth = 8 scores are : [0.80025981 0.80975031 0.79846313 0.80527481 0.80632002]\n",
      "=========================================\n",
      "training for depth = 15\n",
      "for depth = 15 scores are : [0.86058851 0.86452152 0.85933953 0.86518803 0.85727826]\n",
      "=========================================\n",
      "The depth is:  15\n",
      "################____RF____#################\n",
      "training for 100 trees\n",
      "for 100 trees scores are : [0.96571259 0.9635131  0.96440118 0.96285871 0.96681695]\n",
      "=========================================\n",
      "training for 500 trees\n",
      "for 500 trees scores are : [0.9668079  0.96708214 0.96672265 0.96455033 0.9696471 ]\n",
      "=========================================\n",
      "The best num of trees is:  500\n",
      "################____MLP____#################\n",
      "training for Depth:0, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15\n",
      "for Depth:0, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15 mean score is : 0.8724698280246124\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30\n",
      "for Depth:0, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30 mean score is : 0.8890157139693442\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15\n",
      "for Depth:0, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15 mean score is : 0.8897884182645952\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30\n",
      "for Depth:0, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30 mean score is : 0.9045428449727475\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:relu, Num of Epocs:25, Batch Size:15\n",
      "for Depth:0, Activation Function:relu, Num of Epocs:25, Batch Size:15 mean score is : 0.035476904557302555\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:relu, Num of Epocs:25, Batch Size:30\n",
      "for Depth:0, Activation Function:relu, Num of Epocs:25, Batch Size:30 mean score is : 0.06841115253417357\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:relu, Num of Epocs:50, Batch Size:15\n",
      "for Depth:0, Activation Function:relu, Num of Epocs:50, Batch Size:15 mean score is : 0.020338109356345273\n",
      "=========================================\n",
      "training for Depth:0, Activation Function:relu, Num of Epocs:50, Batch Size:30\n",
      "for Depth:0, Activation Function:relu, Num of Epocs:50, Batch Size:30 mean score is : 0.0524736941947774\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15\n",
      "for Depth:1, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15 mean score is : 0.8715675628990321\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30\n",
      "for Depth:1, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30 mean score is : 0.8926324526799325\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15\n",
      "for Depth:1, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15 mean score is : 0.8889677007145924\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30\n",
      "for Depth:1, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30 mean score is : 0.9053822053071819\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:relu, Num of Epocs:25, Batch Size:15\n",
      "for Depth:1, Activation Function:relu, Num of Epocs:25, Batch Size:15 mean score is : 0.020340685958551576\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:relu, Num of Epocs:25, Batch Size:30\n",
      "for Depth:1, Activation Function:relu, Num of Epocs:25, Batch Size:30 mean score is : 0.05232298644933704\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:relu, Num of Epocs:50, Batch Size:15\n",
      "for Depth:1, Activation Function:relu, Num of Epocs:50, Batch Size:15 mean score is : 0.020537617103082793\n",
      "=========================================\n",
      "training for Depth:1, Activation Function:relu, Num of Epocs:50, Batch Size:30\n",
      "for Depth:1, Activation Function:relu, Num of Epocs:50, Batch Size:30 mean score is : 0.02070756580821505\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15\n",
      "for Depth:7, Activation Function:sigmoid, Num of Epocs:25, Batch Size:15 mean score is : 0.020154212292129655\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30\n",
      "for Depth:7, Activation Function:sigmoid, Num of Epocs:25, Batch Size:30 mean score is : 0.01941162375632829\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15\n",
      "for Depth:7, Activation Function:sigmoid, Num of Epocs:50, Batch Size:15 mean score is : 0.01921255805558271\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30\n",
      "for Depth:7, Activation Function:sigmoid, Num of Epocs:50, Batch Size:30 mean score is : 0.020081765165077897\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:relu, Num of Epocs:25, Batch Size:15\n",
      "for Depth:7, Activation Function:relu, Num of Epocs:25, Batch Size:15 mean score is : 0.9507402516341135\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:relu, Num of Epocs:25, Batch Size:30\n",
      "for Depth:7, Activation Function:relu, Num of Epocs:25, Batch Size:30 mean score is : 0.9485595035923156\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:relu, Num of Epocs:50, Batch Size:15\n",
      "for Depth:7, Activation Function:relu, Num of Epocs:50, Batch Size:15 mean score is : 0.9527279235008697\n",
      "=========================================\n",
      "training for Depth:7, Activation Function:relu, Num of Epocs:50, Batch Size:30\n",
      "for Depth:7, Activation Function:relu, Num of Epocs:50, Batch Size:30 mean score is : 0.9519217424356275\n",
      "=========================================\n",
      "The best number of hidden layers is:  7\n",
      "The best activation function is:  relu\n",
      "The best number of epocs is:  50\n",
      "The best batchsize is:  15\n",
      "========================Selection Between DT, RF, and MLP==========================\n",
      "Decision Tree Classification Performance:  0.8613831716103608\n",
      "=========================================\n",
      "Random Forest Classifier Classification Performance:  0.9665362143782851\n",
      "=========================================\n",
      "MLP Classifier Classification Performance:  0.93859088418216\n",
      "=========================================\n",
      "The best model is learnt by Random Forest Classifier!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The best model will be selected among {DT, Decision Tree, and MLP}\n",
    "However, beforehand:\n",
    "(-For KNN the best model with respect to different values of K will be selected)\n",
    "-For DT the best model with respect to different values of max depth will be selected\n",
    "-For DT the best model with respect to different number of trees will be selected\n",
    "-For MLP the best model with respect to \"different number of hidden layes\", \n",
    "\"types of activation functions\" , \"number of epocs\", and \"batchsize\" will be selected\n",
    "\n",
    "'''\n",
    "# Model Selection\n",
    "model_index, model = final_model_select(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Performance for test set is:  0.9708338999042571\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "if model_index==0: #DT\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_Y = model.predict(X_test)\n",
    "    Classification_Performance = f1_score(Y_test, pred_Y, average='macro')\n",
    "elif model_index==1: #RF\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_Y = model.predict(X_test)\n",
    "    Classification_Performance = f1_score(Y_test, pred_Y, average='macro')\n",
    "else: #MLP\n",
    "    num_classes = 10\n",
    "    Y_train_cat = to_categorical(Y_train, num_classes)\n",
    "    Y_test_cat = to_categorical(Y_test, num_classes)\n",
    "    model.fit(X_train, Y_train_cat)\n",
    "    pred_Y = model.predict(Y_test_cat)\n",
    "    Classification_Performance = f1_score(Y_test, pred_Y, average='macro')\n",
    "    \n",
    "print(\"The Classification Performance for test set is: \", Classification_Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "THE FINAL MODEL IS GENERATED!\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Train the selected model on the whole data (there will be no evaluation)\n",
    "if model_index==0: #DT\n",
    "    model.fit(data, labels)\n",
    "elif model_index==1: #RF\n",
    "    model.fit(data, labels)\n",
    "else: #MLP\n",
    "    num_classes = 10\n",
    "    labels_cat = to_categorical(labels, num_classes)\n",
    "    model.fit(data, labels_cat)\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"THE FINAL MODEL IS GENERATED!\")\n",
    "print(\"=========================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
